å¥½çš„âœ… æˆ‘å¸®ä½ æŠŠæ–‡æ¡£é‡æ–°æ•´ç†äº†ä¸€ä¸‹ï¼Œæ’ç‰ˆæ¸…æ™°ã€ç›®å½•å¸¦é“¾æ¥ã€æ–‡å­—æ›´ç®€æ´æµç•…ï¼Œä¾¿äºå­¦ä¹ å’ŒæŸ¥é˜…ã€‚

---

# ç¬¬äº”éƒ¨åˆ†ï¼šè®­ç»ƒä¸å¾®è°ƒ

æˆ‘ä»¬æ­£å¼è¿›å…¥ **ç¬¬äº”éƒ¨åˆ†ï¼šè®­ç»ƒä¸å¾®è°ƒ**ã€‚

ç›®å‰å·²æœ‰è®¸å¤šè®­ç»ƒå’Œå¾®è°ƒå·¥å…·ï¼Œå…¶ä¸­æœ€è‘—åçš„å°±æ˜¯ **[LLaMA-Factory](https://llamafactory.readthedocs.io/zh-cn/latest/)**ã€‚å®ƒé…ç½®å¥½æ–‡ä»¶å’Œæ•°æ®å³å¯å®Œæˆè®­ç»ƒï¼Œéå¸¸å¥½ç”¨ã€‚ä½†ä¸ºäº†å­¦ä¹ ç›®çš„ï¼Œæˆ‘ä»¬å…ˆä»åŸç†å‡ºå‘ï¼Œç†è§£å¦‚ä½•è¿›è¡Œè®­ç»ƒå’Œå¾®è°ƒï¼Œå†å­¦ä¹ å¦‚ä½•ä½¿ç”¨è¿™äº›å·¥å…·ã€‚

ç”±äºé¡¹ç›®å’Œå°±ä¸šåœºæ™¯ä¸»è¦ä¾èµ–å¼€æºæ¨¡å‹ï¼Œæœ¬èŠ‚é‡ç‚¹ä»¥ **Qwen ç³»åˆ—æ¨¡å‹** ä¸ºä¸»è¿›è¡Œè®²è§£ä¸å®è·µã€‚

---

## ğŸ“š å‚è€ƒèµ„æ–™

* [LLaMA-Factory å®˜æ–¹æ–‡æ¡£](https://llamafactory.readthedocs.io/zh-cn/latest/)
* [Qwen3 å¿«é€Ÿå…¥é—¨æ–‡æ¡£](https://qwen.readthedocs.io/zh-cn/latest/getting_started/quickstart.html)

---

## ğŸ“‘ ç›®å½•

1. [ç¯å¢ƒå‡†å¤‡](#ç¯å¢ƒå‡†å¤‡)
2. [æ•°æ®å¤„ç†](#æ•°æ®å¤„ç†)
   * [Alpaca æ ¼å¼](#alpaca-æ ¼å¼)
   * [ShareGPT æ ¼å¼](#sharegpt-æ ¼å¼)
3. [æ¨¡å‹çš„ä¸‹è½½ä¸æ¨ç†](#æ¨¡å‹çš„ä¸‹è½½ä¸æ¨ç†)
4. [é¢„è®­ç»ƒ](#é¢„è®­ç»ƒ)
5. [å¾®è°ƒ](#å¾®è°ƒ)

---

## ç¯å¢ƒå‡†å¤‡

* Python â‰¥ 3.10
* PyTorch â‰¥ 2.6
* `transformers` â‰¥ 4.51.0

---

## æ•°æ®å¤„ç†

æ•°æ®çš„æ ¸å¿ƒåœ¨äº **`dataset_info.json`**ï¼Œå®ƒå®šä¹‰äº†æ‰€æœ‰æ•°æ®é›†ï¼ˆæœ¬åœ° & åœ¨çº¿ï¼‰çš„ä¿¡æ¯ã€‚

ğŸ‘‰ å¦‚æœä½ éœ€è¦ä½¿ç”¨è‡ªå®šä¹‰æ•°æ®é›†ï¼Œè¯·åŠ¡å¿…åœ¨ `./dataset/dataset_info.json` ä¸­æ·»åŠ ç›¸åº”æè¿°ã€‚

ç›®å‰æ”¯æŒä¸¤å¤§ä¸»è¦æ ¼å¼ï¼š

* **Alpaca æ ¼å¼**
* **ShareGPT æ ¼å¼**

æ­¤å¤–ï¼Œè¿˜æ”¯æŒ **å¤šæ¨¡æ€æ•°æ®é›†**ï¼ˆå›¾åƒ/è§†é¢‘/éŸ³é¢‘ï¼‰ã€**åå¥½æ•°æ®é›†**ã€**KTO æ•°æ®é›†** ç­‰ã€‚

---

### Alpaca æ ¼å¼

Alpaca æ ¼å¼é€‚åˆ **æŒ‡ä»¤ç›‘ç£å¾®è°ƒ**ã€**é¢„è®­ç»ƒ**ã€**åå¥½è®­ç»ƒ**ã€**KTO**ã€**å¤šæ¨¡æ€ä»»åŠ¡**ã€‚

#### 1. æŒ‡ä»¤ç›‘ç£å¾®è°ƒ

æ¨¡å‹å­¦ä¹ è¾“å…¥æŒ‡ä»¤ä¸è¾“å‡ºå›ç­”çš„å¯¹åº”å…³ç³»ã€‚
åŸºæœ¬å­—æ®µï¼š

* `instruction`ï¼ˆå¿…å¡«ï¼‰ï¼šäººç±»æŒ‡ä»¤
* `input`ï¼ˆé€‰å¡«ï¼‰ï¼šé¢å¤–è¾“å…¥
* `output`ï¼ˆå¿…å¡«ï¼‰ï¼šæ¨¡å‹å›ç­”
* `system`ï¼ˆé€‰å¡«ï¼‰ï¼šç³»ç»Ÿæç¤ºè¯
* `history`ï¼ˆé€‰å¡«ï¼‰ï¼šå¤šè½®å¯¹è¯å†å²

**ç¤ºä¾‹ï¼š**

```json
[
  {
    "instruction": "è®¡ç®—è¿™äº›ç‰©å“çš„æ€»è´¹ç”¨ã€‚",
    "input": "æ±½è½¦ - $3000ï¼Œè¡£æœ - $100ï¼Œä¹¦ - $20ã€‚",
    "output": "æ€»è´¹ç”¨ä¸º $3120ã€‚",
    "history": [
      ["ä»Šå¤©ä¼šä¸‹é›¨å—ï¼Ÿ", "ä¸ä¼šï¼Œä¸‹é›¨æœºç‡ä¸º0ã€‚"],
      ["é€‚åˆå‡ºé—¨å—ï¼Ÿ", "å¾ˆé€‚åˆã€‚"]
    ]
  }
]
```

**å¯¹åº” `dataset_info.json`ï¼š**

```json
"æ•°æ®é›†åç§°": {
  "file_name": "data.json",
  "columns": {
    "prompt": "instruction",
    "query": "input",
    "response": "output",
    "system": "system",
    "history": "history"
  }
}
```

#### 2. é¢„è®­ç»ƒæ•°æ®é›†

```json
[
  {"text": "è¿™æ˜¯ç¬¬ä¸€æ®µè®­ç»ƒæ–‡æœ¬ã€‚"},
  {"text": "è¿™æ˜¯ç¬¬äºŒæ®µè®­ç»ƒæ–‡æœ¬ã€‚"}
]
```

`dataset_info.json`ï¼š

```json
"æ•°æ®é›†åç§°": {
  "file_name": "data.json",
  "columns": {
    "prompt": "text"
  }
}
```

#### 3. åå¥½æ•°æ®é›†

ç”¨äº **å¥–åŠ±å»ºæ¨¡**ã€**DPO/ORPO è®­ç»ƒ**ã€‚

```json
[
  {
    "instruction": "äººç±»æŒ‡ä»¤",
    "chosen": "æ›´ä¼˜çš„å›ç­”",
    "rejected": "è¾ƒå·®çš„å›ç­”"
  }
]
```

#### 4. KTO æ•°æ®é›†

```json
[
  {
    "instruction": "äººç±»æŒ‡ä»¤",
    "output": "æ¨¡å‹å›ç­”",
    "kto_tag": true
  }
]
```

#### 5. å¤šæ¨¡æ€æ•°æ®é›†

æ”¯æŒ **å›¾åƒ / è§†é¢‘ / éŸ³é¢‘** è¾“å…¥ï¼Œéœ€åœ¨ JSON ä¸­åŠ å…¥ `images` / `videos` / `audios` å­—æ®µã€‚

---

### ShareGPT æ ¼å¼

ShareGPT æ ¼å¼ç›¸æ¯” Alpaca æ›´çµæ´»ï¼Œæ”¯æŒæ›´å¤šè§’è‰²ï¼ˆ`human`ã€`gpt`ã€`function_call`ã€`observation` ç­‰ï¼‰ã€‚

#### 1. æŒ‡ä»¤ç›‘ç£å¾®è°ƒ

```json
{
  "conversations": [
    {"from": "human", "value": "ä½ å¥½"},
    {"from": "gpt", "value": "ä½ å¥½ï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼"}
  ]
}
```

#### 2. åå¥½æ•°æ®é›†

```json
{
  "conversations": [
    {"from": "human", "value": "è€è™åƒè‰å—ï¼Ÿ"}
  ],
  "chosen": {"from": "gpt", "value": "è€è™æ˜¯é£Ÿè‚‰åŠ¨ç‰©ã€‚"},
  "rejected": {"from": "gpt", "value": "è€è™ä¸»è¦åƒè‰ã€‚"}
}
```

#### 3. OpenAI æ ¼å¼

ä¸€ç§ç‰¹æ®Šæƒ…å†µï¼Œ`messages` å­—æ®µä¸­åŒ…å« `system`ã€`user`ã€`assistant`ï¼š

```json
{
  "messages": [
    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹"},
    {"role": "user", "content": "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"},
    {"role": "assistant", "content": "ä»Šå¤©æ˜¯æ™´å¤©ã€‚"}
  ]
}
```

 
---

## æ¨¡å‹çš„ä¸‹è½½ä¸æ¨ç†

åœ¨å›½å†…ç›´æ¥ä» HuggingFace ä¸‹è½½æ¨¡å‹æ—¶ï¼Œç»å¸¸ä¼šé‡åˆ°ç½‘ç»œä¸ç¨³å®šã€æ–­ç‚¹ä¸‹è½½å¤±è´¥ç­‰é—®é¢˜ã€‚ä¸ºäº†é¿å…è¿™äº›æƒ…å†µï¼Œå¯ä»¥ **é…ç½®å›½å†…é•œåƒæº** å¹¶ **æŒ‡å®šç¼“å­˜è·¯å¾„** æ¥ä¿è¯ä¸‹è½½è¿‡ç¨‹æ›´ç¨³å®šã€æ›´å¯æ§ã€‚

---

### ğŸ“Œ é…ç½®å›½å†…æºä¸ç¼“å­˜è·¯å¾„

```python
import os
from huggingface_hub import snapshot_download

# é…ç½®å›½å†…é•œåƒï¼ˆhf-mirrorï¼‰ï¼Œæå‡ä¸‹è½½æˆåŠŸç‡
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"

# è®¾ç½®æœ¬åœ°ç¼“å­˜ç›®å½•ï¼ˆå¯é€‰ï¼Œä¸è®¾ç½®åˆ™é»˜è®¤ ~/.cache/huggingface/ï¼‰
os.environ["HF_HOME"] = r"./models"

# æ¨¡å‹åç§°
model_name = "Qwen/Qwen3-0.6B"
# æœ¬åœ°ç›®æ ‡ç›®å½•
target_dir = r"./models/Qwen3-0.6B"

# ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°ï¼ˆsnapshot_download ä¼šè‡ªåŠ¨æ–­ç‚¹ç»­ä¼ ï¼‰
snapshot_download(
    repo_id=model_name,
    local_dir=target_dir,
    local_dir_use_symlinks=False  # é¿å…ç¬¦å·é“¾æ¥ï¼Œä¿è¯çœŸå®æ–‡ä»¶è½åœ°
)
```

---

### ğŸ“Œ åŠ è½½æ¨¡å‹ä¸æ¨ç†

æ¨¡å‹ä¸‹è½½å®Œæˆåï¼Œå¯ä»¥ç›´æ¥ä»æœ¬åœ°ç›®å½•åŠ è½½ï¼Œé¿å…é‡å¤è”ç½‘ï¼š

```python
from transformers import AutoModelForCausalLM, AutoTokenizer

# ä»æœ¬åœ°è·¯å¾„åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨
tokenizer = AutoTokenizer.from_pretrained(target_dir, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(
    target_dir,
    device_map="auto",
    torch_dtype="auto",
    trust_remote_code=True
)

# æµ‹è¯•æ¨ç†
prompt = "è¯·ç”¨ç®€çŸ­çš„è¯ä»‹ç»ä¸€ä¸‹å¤§è¯­è¨€æ¨¡å‹çš„ä½œç”¨ã€‚"
inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
outputs = model.generate(**inputs, max_new_tokens=128)

print(tokenizer.decode(outputs[0], skip_special_tokens=True))
```
 
---

# æ¨¡å‹ç”Ÿæˆéƒ¨åˆ†æ€»ç»“

### 1. åŠ è½½ Tokenizer å’Œæ¨¡å‹

```python
# æŒ‡å®šæ¨¡å‹ä¿å­˜è·¯å¾„
local_dir = "./models/Qwen3-0.6B"

# åŠ è½½ tokenizer å’Œæ¨¡å‹
tokenizer = AutoTokenizer.from_pretrained(local_dir)
model = AutoModelForCausalLM.from_pretrained(
    local_dir,
    torch_dtype="auto",
    device_map="cuda:0"
)
```

---

### 2. æ„é€ è¾“å…¥æ–‡æœ¬

```python
messages = [
    {"role": "system", "content": SYS_PROMPT},
    {"role": "user", "content": prompt}
]

text = tokenizer.apply_chat_template(
    messages,
    tokenize=False,
    add_generation_prompt=True,
    enable_thinking=True  # å¯ç”¨æ€è€ƒæ¨¡å¼
)
```

æ­¤æ—¶è¾“å…¥ä¼šè¢«è½¬åŒ–ä¸ºä»¥ä¸‹å½¢å¼ï¼š

```
<|im_start|>system
SYS_PROMPT
<|im_end|>
<|im_start|>user
prompt
<|im_end|>
<|im_start|>assistant
```

è¿™ç§æ ‡æ³¨æ–¹å¼èƒ½è®©å¤§æ¨¡å‹æ›´å¥½åœ°ç†è§£**å¤šè½®å¯¹è¯çš„è§’è‰²å’Œè½®æ¬¡**ã€‚æœ€åçš„ `<|im_start|>assistant` è¡¨æ˜ï¼šç°åœ¨è½®åˆ°æ¨¡å‹å›ç­”ã€‚

---

### 3. Tokenizer å°†æ–‡å­—è½¬åŒ–ä¸º token

```python
model_inputs = tokenizer([text], return_tensors="pt").to(model.device)
```

è¾“å‡ºç¤ºä¾‹ï¼š

```
{
  'input_ids': tensor([[151644,   8948, ...]], device='cuda:0'),
  'attention_mask': tensor([[1, 1, ...]], device='cuda:0')
}
```

---

### 4. æ¨¡å‹ç”Ÿæˆ

```python
generated_ids = model.generate(
    **model_inputs,
    max_new_tokens=32768
)
```

ç»“æœæ˜¯ä¸€ä¸ª **token åºåˆ—**ï¼Œå¦‚ï¼š

```
tensor([[151644,   8948,   271, ...,   532, 73594, 151645]], device='cuda:0')
```

---

### 5. æˆªå–è¾“å‡ºéƒ¨åˆ†

åªå–æ–°å¢çš„è¾“å‡ºï¼ˆè¾“å…¥éƒ¨åˆ†ä¸éœ€è¦é‡å¤ï¼‰ï¼š

```python
output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist()
```

---

### 6. è§£æè¾“å‡ºå†…å®¹

æ¨¡å‹å¯èƒ½åŒ…å« **thinking** å’Œ **content** ä¸¤éƒ¨åˆ†ï¼Œéœ€è¦åˆ†å¼€è§£ç ï¼š

```python
try:
    # æ‰¾åˆ° </think> çš„ token ä½ç½®ï¼ˆåè½¬æœç´¢ï¼Œä¿è¯å–æœ€åä¸€æ¬¡å‡ºç°ï¼‰
    index = len(output_ids) - output_ids[::-1].index(151668)
except ValueError:
    index = 0

thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip("\n")
content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip("\n")
```

---
## âœ… æ€»ç»“

1. **ä¸‹è½½**ï¼š`snapshot_download` å¯æ–­ç‚¹ç»­ä¼ ï¼Œæ¨èå›½å†…ç¯å¢ƒä½¿ç”¨ã€‚
2. **é•œåƒ**ï¼šè®¾ç½® `HF_ENDPOINT=https://hf-mirror.com`ï¼Œå¤§å¹…æé«˜ä¸‹è½½é€Ÿåº¦å’ŒæˆåŠŸç‡ã€‚
3. **ç¼“å­˜è·¯å¾„**ï¼šé€šè¿‡ `HF_HOME` æ§åˆ¶æ¨¡å‹å­˜å‚¨ç›®å½•ï¼Œé¿å…æ¨¡å‹æ•£è½åœ¨é»˜è®¤ç¼“å­˜è·¯å¾„ã€‚
4. **åŠ è½½**ï¼šä¸‹è½½ä¸€æ¬¡åï¼Œç›´æ¥ä»æœ¬åœ°ç›®å½•åŠ è½½å³å¯ï¼Œ**å®Œå…¨ç¦»çº¿æ¨ç†**ã€‚

---

 

 
---

## é¢„è®­ç»ƒ

ä»‹ç»å¦‚ä½•å‡†å¤‡å¤§è§„æ¨¡æœªæ ‡æ³¨æ•°æ®è¿›è¡Œé¢„è®­ç»ƒã€‚

---

## å¾®è°ƒ

ä»‹ç»å¦‚ä½•åŸºäºæŒ‡ä»¤æ•°æ®é›†è¿›è¡Œç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ã€åå¥½å»ºæ¨¡ï¼ˆDPO/ORPOï¼‰ã€KTO ç­‰ã€‚

---

 