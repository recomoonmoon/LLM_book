大模型的训练如何处理数据，提升训练效果？

主要考虑SFT的训练，在后续代码之前分享如何处理数据，优化模型的SFT训练。

首先介绍背景，LLM的预训练阶段主要学习了语言规律和注入知识，这时候的模型可以说是纯纯的基座模型。

LLM的后训练或者说微调阶段的目的是什么？
* 提升模型在某一任务下的能力。

具体说jiux