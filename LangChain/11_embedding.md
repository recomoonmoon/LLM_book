 
---

# Embedding Models

ï¼ˆåµŒå…¥æ¨¡å‹ç¬”è®°ï¼‰

## ğŸ“‘ ç›®å½•

1. [å‰ç½®çŸ¥è¯†](#å‰ç½®çŸ¥è¯†)
2. [æ¦‚å¿µæ¦‚è§ˆ](#æ¦‚å¿µæ¦‚è§ˆ)
3. [å†å²èƒŒæ™¯](#å†å²èƒŒæ™¯)
4. [æ¥å£ä¸ç”¨æ³•](#æ¥å£ä¸ç”¨æ³•)
5. [ç›¸ä¼¼åº¦åº¦é‡](#ç›¸ä¼¼åº¦åº¦é‡)
6. [è¿›ä¸€æ­¥å­¦ä¹ èµ„æº](#è¿›ä¸€æ­¥å­¦ä¹ èµ„æº)

---

## å‰ç½®çŸ¥è¯†

* **Documents**ï¼ˆæ–‡æœ¬æ•°æ®ï¼‰
* Embedding æ¨¡å‹ä¸»è¦é’ˆå¯¹ **æ–‡æœ¬**ï¼Œå°½ç®¡å­˜åœ¨å¤šæ¨¡æ€ embeddingï¼Œä½†ç›®å‰ LangChain ä¸æ”¯æŒå¤šæ¨¡æ€ã€‚

---

## æ¦‚å¿µæ¦‚è§ˆ

Embedding æ¨¡å‹çš„æ ¸å¿ƒåŠŸèƒ½ï¼š

1. **Embed text as a vector**ï¼šå°†æ–‡æœ¬è½¬æ¢ä¸ºå®šé•¿å‘é‡è¡¨ç¤ºï¼ˆè¯­ä¹‰æŒ‡çº¹ï¼‰ã€‚
2. **Measure similarity**ï¼šä½¿ç”¨æ•°å­¦æ–¹æ³•æ¯”è¾ƒå‘é‡ï¼Œè¡¡é‡è¯­ä¹‰ç›¸ä¼¼åº¦ã€‚

ğŸ“Œ ä»·å€¼ï¼š

* ä¸ä»…é™äºå…³é”®è¯åŒ¹é…ï¼Œè€Œæ˜¯åŸºäºè¯­ä¹‰ç†è§£å®ç°æ£€ç´¢ã€èšç±»ã€æ¨èç­‰ä»»åŠ¡ã€‚

---

## å†å²èƒŒæ™¯

* **2018 BERT**ï¼šGoogle æå‡ºï¼Œé¦–æ¬¡ä½¿ç”¨ Transformer ç»“æ„åš embeddingã€‚ â†’ ä½†ä¸é€‚åˆé«˜æ•ˆç”Ÿæˆå¥å­å‘é‡ã€‚
* **SBERT (Sentence-BERT)**ï¼šæ”¹é€  BERTï¼Œä½¿å…¶é«˜æ•ˆç”Ÿæˆè¯­ä¹‰å¥å‘é‡ï¼Œæ”¯æŒä½™å¼¦ç›¸ä¼¼åº¦ç­‰å¿«é€Ÿæ¯”è¾ƒï¼Œå¤§å¹…é™ä½è®¡ç®—æˆæœ¬ã€‚
* **ç°åœ¨**ï¼šembedding æ¨¡å‹ç”Ÿæ€å¤šå…ƒï¼Œç ”ç©¶è€…å¸¸å‚è€ƒ **MTEB (Massive Text Embedding Benchmark)** æ¥æ¯”è¾ƒæ¨¡å‹æ•ˆæœã€‚

---

## æ¥å£ä¸ç”¨æ³•

LangChain æä¾›ç»Ÿä¸€æ¥å£ï¼Œæ ¸å¿ƒæ–¹æ³•æœ‰ï¼š

* `embed_documents`ï¼šå¯¹å¤šä¸ªæ–‡æœ¬ç”Ÿæˆå‘é‡ï¼ˆæ‰¹é‡å¤„ç†ï¼‰ã€‚
* `embed_query`ï¼šå¯¹å•ä¸ªæŸ¥è¯¢ç”Ÿæˆå‘é‡ã€‚

ç¤ºä¾‹ï¼š

```python
from langchain_openai import OpenAIEmbeddings

# åˆå§‹åŒ–æ¨¡å‹
embeddings_model = OpenAIEmbeddings()

# æ–‡æ¡£æ‰¹é‡ embedding
embeddings = embeddings_model.embed_documents([
    "Hi there!",
    "Oh, hello!",
    "What's your name?",
    "My friends call me World",
    "Hello World!"
])

print(len(embeddings), len(embeddings[0]))  # (5, 1536)

# æŸ¥è¯¢ embedding
query_embedding = embeddings_model.embed_query("What is the meaning of life?")
```

ğŸ“Œ æ³¨æ„ï¼šéƒ¨åˆ† embedding æœåŠ¡å¯¹ **æŸ¥è¯¢** å’Œ **æ–‡æ¡£** ä½¿ç”¨ä¸åŒç­–ç•¥ã€‚

---

## ç›¸ä¼¼åº¦åº¦é‡

Embedding å‘é‡ä½äºé«˜ç»´è¯­ä¹‰ç©ºé—´ï¼Œå¸¸è§åº¦é‡æ–¹æ³•ï¼š

1. **Cosine Similarity**ï¼šè§’åº¦ç›¸ä¼¼æ€§ï¼Œæœ€å¸¸ç”¨ã€‚
2. **Euclidean Distance**ï¼šæ¬§å¼è·ç¦»ï¼Œç›´çº¿è·ç¦»ã€‚
3. **Dot Product**ï¼šç‚¹ç§¯ï¼Œåæ˜ æŠ•å½±å…³ç³»ã€‚

ç¤ºä¾‹ï¼ˆä½™å¼¦ç›¸ä¼¼åº¦ï¼‰ï¼š

```python
import numpy as np

def cosine_similarity(vec1, vec2):
    dot_product = np.dot(vec1, vec2)
    norm_vec1 = np.linalg.norm(vec1)
    norm_vec2 = np.linalg.norm(vec2)
    return dot_product / (norm_vec1 * norm_vec2)

similarity = cosine_similarity(query_embedding, embeddings[0])
print("Cosine Similarity:", similarity)
```

---

## è¿›ä¸€æ­¥å­¦ä¹ èµ„æº

* [BERT åŸå§‹è®ºæ–‡](https://arxiv.org/abs/1810.04805)
* Cameron Wolfe çš„ embedding æ¨¡å‹ç»¼è¿°
* [MTEB Leaderboard](https://huggingface.co/spaces/mteb/leaderboard)

---

 